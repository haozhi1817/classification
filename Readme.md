<!--
 * @Author: HaoZhi
 * @Date: 2022-08-11 16:49:30
 * @LastEditors: HaoZhi
 * @LastEditTime: 2022-10-14 09:44:17
 * @Description: 
-->

# 数据集

## 类别分布

| | 没有佩戴 | 错误佩戴 | 正确佩戴 |
| --- | --- | --- | --- |
| 训练集 | 3493 | 2878 | 2979 |
| 测试集 | 518 | 263 | 479 |

## size分布

![统计结果](.utils\img_szie.png)

训练集：99-1880
测试集：90-1425


| | ResNet50 | ConvNext-S | ConvNext-T |AlterNet50 | SwinTransFormer-T | CoATNet-2 | EfficientNet-b1 |
| --- | --- | --- | --- | --- | --- | --- | --- |
| Total params |23,514,179 | 49,456,995 | 27,822,435 |58,906,937 | 1,562,403 | 54,744,642 | 6,517,027 |
| Total mult-adds (M)| 4.14(G) | 503.61 | 372.83 |8.01(G) | 114.24 | 2.24(G) | 586.58 |
| Forward/backward pass size (MB) | 169.59 |197.54|125.19|142.02| 43.64 | 80.77 | 142.53 |
| Params size (MB) | 89.70 | 188.66 | 106.13 | 224.71 | 5.96 | 208.83 | 24.86 | 
| Estimated Total Size (MB)| 259.86 |386.77| 231.89 | 367.31 | 51.59 | 290.18 | 167.96 |

# 实验记录

| 模型名称 | 损失函数 | data size | 没有佩戴 | 错误佩戴 | 正确佩戴 | 平均召回 |
| --- | --- | --- | --- | --- | --- | --- |
| ResNet50 | CeLoss | 36  * 224 *224 * 3 | 79.15% | 90.11% | 75.16% | 81.47% |
| ResNet50_unbalance_dataset | CeLoss | 36  * 224 *224 * 3 | 79.92% | 89.74% | 75.16% | 81.60% |
| ConvNext-T | CeLoss | 36 * 224 * 224 * 3 | 79.92% | 89.74% | 75.99% | 81.88% |
| SwinTransformer-T | CeLosss | 36 * 224 * 224 * 3 | 79.34% | 89.73% | 75.99% | 81.69% |
| AlterNet50 | CeLoss | 36 *224 * 224 * 3 | 80.31% | 90.11% | 74.95% | 81.80% | 
| Efficientb1| CeLoss | 36 * 224 * 224 * 3 | 79.34% | 90.11% | 74.53% | 81.3% |
| CoATNet-2 | CeLoss | 9 * 224 * 224 * 3 | 81.27% | 90.11 % | 72.86% | 81.41% |
| MaxVit-s | CeLoss | 9 * 224 * 224 * 3 | 79.34% | 90.11% | 74.53% | 81.32% |

| | 没有佩戴 | 正确佩戴 | 错误佩戴 |
| --- | --- | --- | --- |
| 没有佩戴 | 416 | 71 | 31 |
| 正确佩戴 |81 | 359 | 39 |
| 错误佩戴 |17 | 9 | 237 |

## 总结

* 利用torchsummary计算的模型容量差异巨大，但是在实际训练过程中，batch size相同的情况下，显存占用几乎一致。                                                                                                                                                                  
* 纯Transformer结构对学习率非常敏感，学习率较大时，模型几乎不收敛，一般选择1e-4。
* 在该项目中，由于数据没有明显的不平衡，因此是否对数据在采样时进行人工平衡，对最终结果没有影响。
* 纯Transformer结构的模型训练速度比较慢。
* 模型参数： ResNet50 < SwinTransFormer = ConvNext < AlterNet
* 测试集中存在明显的标签错误，在错误佩戴这一类别中尤为明显。
* 4个模型的结果差异不大。
* 明显错误集中在（没有佩戴---正确佩戴）类别间。
* EfficientNet的模型参数明显少于其他任何模型。
* 大多数情况下，一些模型前期会在个别类别上表现很好，其他类别也没有非常差，但是到了后期基本上每一个类别表现都是比较稳定在一个中间状态。
* 没太注意到其他模型训练过程中的结果，但是maxvit明显在前100个epoch一直在找不同的特征，表现为训练集收敛很好，测试集波动巨大。
* 观察CNN（resnet50）的训练过程，较之于maxvit，收敛更快，更稳定。但是值得注意的事，VIT类模型在训练集上的表现一般会由于CNN类模型，可能是大数据对于VIT更加友好。

# Image Size / Window Size / Patch Size

| 模型名称 | 损失函数 | data size | 没有佩戴 | 错误佩戴 | 正确佩戴 | 平均召回 |
| --- | --- | --- | --- | --- | --- | --- |
| ResNet50 | CeLoss | 9 * 448 * 448 | 80.12% | 90.87% | 79.29% | 81.98% |
| SwinTransFormer | CeLoss | 9 * 488 * 488 | 77.80% | 90.11% | 75.78% |  77.80% |
| SwinTransFormer | CeLoss | 9 * 488 * 488, patch-size = 8, window-size = 7, | 80.69% | 90.49% | 76.61% | 81.19% |
| SwinTransFormer | CeLoss | 6 * 488 * 488, patch-size = 4, window-size = 14, | 78.96% | 90.49% | 72.86% | 80.77% |

* patch_size越大，下采样越严重，显存占用越小，训练速度越快。
* window_size越大，越占显存，同时训练速度越慢。

# DataAug

| 模型名称 | 损失函数 | data size | 数据增强 |没有佩戴 | 错误佩戴 | 正确佩戴 | 平均召回 |
| --- | --- | --- | --- | --- | --- | --- | --- |
| ResNet50 | CeLoss | 36 * 224 * 224 | LabelSmooth | 79.15% | 90.11% | 74.74% | 81.33% |
| ResNet50 | CeLoss | 36 * 448 * 448 | RandomAug | 80.69% | 90.87% | 75.57% | 82.00% |
| ResNet50 | CeLoss | 36 * 448 * 448 | MixUp | 79.7% | 90.49% | 75.57% | 81.93% |

* RandomAug效果优于TrivialAugment
* MixUp对结果也有一些帮助，似乎本任务数据较少，容易过拟合，越大的数据增强力度，效果越好，
* LabelSmooth 在早期（epoch = 6）时，有平均83~84%的优异表现，但是后期逐渐变差

# Loss

| 模型名称 | 损失函数 | data size |没有佩戴 | 错误佩戴 | 正确佩戴 | 平均召回 |
| --- | --- | --- | --- | --- | --- | --- |
| ResNet50 | Focal Loss | 36 * 224 * 224 | 79.53% | 89.73% | 74.74% | 81.34% |

# LrScheduler
| 模型名称 | 损失函数 | data size | LrScheduler |没有佩戴 | 错误佩戴 | 正确佩戴 | 平均召回 |
| --- | --- | --- | --- | --- | --- | --- | --- |
| ResNet50 | CeLoss | 36 * 224 * 224 | CosRestart | 78.76% | 90.49% | 76.41% | 81.89% |

# TTA

## resnet50 + label_smooth + img_size_224

### epoch-5
  |img_size = 224 | 没有佩戴 | 正确佩戴 | 错误佩戴 |
| --- | --- | --- | --- |
| 没有佩戴 | 421 | 75 | 22 |
| 正确佩戴 |67 | 382 | 30 |
| 错误佩戴 |12 | 15 | 236 |

|img_size = 448 | 没有佩戴 | 正确佩戴 | 错误佩戴 |
| --- | --- | --- | --- |
| 没有佩戴 | 345 | 97 | 76 |
| 正确佩戴 |39 | 355 | 85 |
| 错误佩戴 |6 | 39 | 218 |

### epoch-199
  |img_size = 224 | 没有佩戴 | 正确佩戴 | 错误佩戴 |
| --- | --- | --- | --- |
| 没有佩戴 | 409 | 78 | 31 |
| 正确佩戴 |86 | 358 | 35 |
| 错误佩戴 |16 | 10 | 237 |

|img_size = 448 | 没有佩戴 | 正确佩戴 | 错误佩戴 |
| --- | --- | --- | --- |
| 没有佩戴 | 484 | 24 | 10 |
| 正确佩戴 |177 | 279 | 23 |
| 错误佩戴 |81 | 16 | 166 |

* 过拟合的另一种表现形式，TTA失效。上次注意到这种情况是数据极具不平衡，利用平衡sampler强制训练过程中数据平衡。